{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdf9d6-9e7e-41a7-a99a-708373db4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script implements a Contextual Bandit–style classification approach using a DQN architecture\n",
    "on HUMS2023 vibration signals. The goal is to classify each signal segment as \"Normal\" or \"Faulty\" based\n",
    "on a simple reward structure (reward = +1 if the predicted label matches the ground truth, otherwise –1).\n",
    "Although framed as a DQN, the discount factor (gamma) is set to 0, effectively reducing this to a\n",
    "contextual bandit that selects an action (label) for a given signal.\n",
    "\n",
    "Note:\n",
    "\n",
    "    - Training sequences are loaded from two folders:\n",
    "        1. './data/Contextual_bandit/Normal_19_20'  (labels = 0 for normal signals, days 19 and 20\n",
    "        2. './data/Contextual_bandit/Faulty_26_27'  (labels = 1 for faulty signals, days 26–27)\n",
    "      Unlabeled test data for days 21–25 are loaded from:\n",
    "        './data/Contextual_bandit/unknown21_25'\n",
    "    - The model input dimensionality is 4095, flattened and the output is a binary choice (0 = Normal, 1 = Faulty).\n",
    "    - Final predictions on the test set are saved as a NumPy file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_signals(folder):\n",
    "    \"\"\"\n",
    "    Load and flatten vibration signals from .mat files in a specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Path to the directory containing .mat files. Each .mat file\n",
    "                      should contain a variable 'xr' representing a 1D vibration signal.\n",
    "\n",
    "    Returns:\n",
    "        signals (np.ndarray): Array of shape (N, signal_length), where N is the number of .mat files\n",
    "        and signal_length is the length of each 'xr' array.\n",
    "        files (List[str]):     Sorted list of full file paths corresponding to each signal.\n",
    "    \"\"\"\n",
    "    signals = []\n",
    "    files = sorted(glob.glob(os.path.join(folder, '*.mat')))\n",
    "    for file in files:\n",
    "        data = loadmat(file)\n",
    "        if 'xr' in data:\n",
    "            xr = data['xr'].astype(np.float32).flatten()\n",
    "            signals.append(xr)\n",
    "    return np.array(signals), files\n",
    "\n",
    "train_normal, _ = load_signals('./data/Contextual_bandit/Normal_19_20')   # days 1–20\n",
    "train_faulty, _ = load_signals('./data/Contextual_bandit/Faulty_26_27')   # days 26–27\n",
    "test_data, test_files = load_signals('./data/Contextual_bandit/unknown21_25') # unlabeled test (Day 21-25)\n",
    "\n",
    "X_train = np.vstack([train_normal, train_faulty])\n",
    "y_train = np.hstack([np.zeros(len(train_normal)), np.ones(len(train_faulty))])\n",
    "\n",
    "mean, std = X_train.mean(), X_train.std()\n",
    "X_train = (X_train - mean) / std\n",
    "test_data = (test_data - mean) / std\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    DQN for contextual bandit classification.\n",
    "\n",
    "    The network takes a flattened 1D vibration signal of length 4096 (with one step implicitly removed,\n",
    "    so input_dim = 4095) and outputs two Q-values corresponding to the two actions:\n",
    "        0: classify as Normal\n",
    "        1: classify as Faulty\n",
    "    Args:\n",
    "        input_dim (int):   Dimensionality of the flattened input signal (default 4095).\n",
    "        hidden_dim (int):  Number of units in the first hidden layer (default 256).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=4095, hidden_dim=256):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the DQN.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output Q-values of shape (batch_size, 2).\n",
    "        \"\"\"\n",
    "        return self.fc(x)\n",
    "\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "epsilon, epsilon_min, epsilon_decay = 1.0, 0.05, 0.995\n",
    "gamma = 0\n",
    "batch_size = 64\n",
    "memory = []\n",
    "\n",
    "def remember(state, action, reward):\n",
    "    \"\"\"\n",
    "    Store an experience tuple (state, action, reward) in replay memory.\n",
    "\n",
    "    Args:\n",
    "        state (torch.Tensor): Tensor of shape (input_dim,) representing the current state.\n",
    "        action (int):         Chosen action (0 for normal, 1 for faulty).\n",
    "        reward (int or float): Scalar reward received for this action.\n",
    "    \"\"\"\n",
    "    memory.append((state, action, reward))\n",
    "\n",
    "def replay():\n",
    "    \"\"\"\n",
    "    Sample a random batch from memory and perform a gradient descent step on the\n",
    "    DQN using the stored (state, action, reward) tuples. Since gamma = 0, the target\n",
    "    Q-value equals the immediate reward for the chosen action.\n",
    "\n",
    "    If the replay buffer has fewer than batch_size entries, this function returns immediately.\n",
    "    \"\"\"\n",
    "    if len(memory) < batch_size: return\n",
    "    batch = np.random.choice(len(memory), batch_size, replace=False)\n",
    "    states, actions, rewards = zip(*[memory[i] for i in batch])\n",
    "    states = torch.stack(states)\n",
    "    actions = torch.tensor(actions).unsqueeze(1).to(device)\n",
    "    rewards = torch.tensor(rewards).unsqueeze(1).to(device).float()\n",
    "\n",
    "    q_values = policy_net(states).gather(1, actions)\n",
    "    loss = criterion(q_values, rewards)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(len(X_train))\n",
    "    total_reward = 0\n",
    "    for idx in perm:\n",
    "        state = X_train[idx]\n",
    "        label = y_train[idx].item()\n",
    "\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice([0,1])\n",
    "        else:\n",
    "            q_vals = policy_net(state.unsqueeze(0))\n",
    "            action = q_vals.argmax().item()\n",
    "\n",
    "        reward = 1 if action == label else -1\n",
    "        remember(state, action, reward)\n",
    "        total_reward += reward\n",
    "\n",
    "        replay()\n",
    "\n",
    "    epsilon = max(epsilon_min, epsilon*epsilon_decay)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs-1:\n",
    "        print(f'Epoch {epoch}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}')\n",
    "g\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "policy_net.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for signal in test_data:\n",
    "        q_vals = policy_net(signal.unsqueeze(0))\n",
    "        pred_label = q_vals.argmax().item()\n",
    "        predictions.append(pred_label)\n",
    "\n",
    "for fname, pred in zip(test_files, predictions):\n",
    "    print(f\"{fname}: {'Faulty' if pred else 'Normal'}\")\n",
    "\n",
    "results = {fname: 'Faulty' if pred else 'Normal' for fname, pred in zip(test_files, predictions)}\n",
    "np.save('predictions_sensorRF2_training1920_test26_27.npy', results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
